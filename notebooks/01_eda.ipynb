{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216d4321",
   "metadata": {},
   "source": [
    "# Spotify Streaming Analytics - Exploratory Data Analysis\n",
    "\n",
    "## Project Overview\n",
    "This notebook provides a comprehensive exploratory data analysis of Spotify streaming history data to replicate real-world Product Analyst workflows. We'll analyze user listening patterns, skip behavior, platform preferences, and generate actionable business insights.\n",
    "\n",
    "**Dataset**: ~150k event-level streaming sessions  \n",
    "**Goal**: Extract insights about user engagement, retention, and behavioral patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1a347",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spotify streaming data\n",
    "data_path = '../data/spotify_history.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic dataset information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset structure and basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nDataset Description:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b75e56",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ceab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Data type analysis\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f33024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique values and potential data quality issues\n",
    "print(\"Unique Value Counts:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"{col}: {unique_count} unique values\")\n",
    "    \n",
    "    # Show top values for categorical columns\n",
    "    if unique_count < 20 and col not in ['spotify_track_uri']:\n",
    "        print(f\"  Top values: {df[col].value_counts().head(5).to_dict()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39029326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and standardization\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove any rows with critical missing values\n",
    "initial_rows = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['spotify_track_uri', 'ts', 'ms_played'])\n",
    "print(f\"Removed {initial_rows - len(df_clean)} rows with missing critical values\")\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "categorical_cols = ['track_name', 'artist_name', 'album_name', 'reason_start', 'reason_end']\n",
    "for col in categorical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "\n",
    "# Convert boolean columns\n",
    "df_clean['shuffle'] = df_clean['shuffle'].map({'TRUE': True, 'FALSE': False})\n",
    "df_clean['skipped'] = df_clean['skipped'].map({'TRUE': True, 'FALSE': False})\n",
    "\n",
    "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Missing values after cleaning: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d555a1f",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Timestamp Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df_clean['timestamp'] = pd.to_datetime(df_clean['ts'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Extract temporal features\n",
    "df_clean['hour_of_day'] = df_clean['timestamp'].dt.hour\n",
    "df_clean['day_of_week'] = df_clean['timestamp'].dt.day_name()\n",
    "df_clean['day_of_week_num'] = df_clean['timestamp'].dt.dayofweek\n",
    "df_clean['month'] = df_clean['timestamp'].dt.month\n",
    "df_clean['year'] = df_clean['timestamp'].dt.year\n",
    "df_clean['date'] = df_clean['timestamp'].dt.date\n",
    "\n",
    "# Convert ms_played to seconds and minutes\n",
    "df_clean['seconds_played'] = df_clean['ms_played'] / 1000\n",
    "df_clean['minutes_played'] = df_clean['seconds_played'] / 60\n",
    "\n",
    "# Create derived metrics\n",
    "# Estimate track length based on maximum play time for each track\n",
    "track_lengths = df_clean.groupby('spotify_track_uri')['ms_played'].max().reset_index()\n",
    "track_lengths.rename(columns={'ms_played': 'estimated_track_length_ms'}, inplace=True)\n",
    "df_clean = df_clean.merge(track_lengths, on='spotify_track_uri', how='left')\n",
    "\n",
    "# Calculate percent played (handling division by zero)\n",
    "df_clean['percent_played'] = np.where(\n",
    "    df_clean['estimated_track_length_ms'] > 0,\n",
    "    (df_clean['ms_played'] / df_clean['estimated_track_length_ms']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Cap percent_played at 100% (some tracks might have been played longer than estimated)\n",
    "df_clean['percent_played'] = np.minimum(df_clean['percent_played'], 100)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New columns added: {list(df_clean.columns[len(df.columns):])}\") \n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional behavioral features\n",
    "# Skip indicator (more refined)\n",
    "df_clean['is_skip'] = (\n",
    "    (df_clean['skipped'] == True) | \n",
    "    (df_clean['percent_played'] < 30) |  # Less than 30% played\n",
    "    (df_clean['reason_end'].isin(['nextbtn', 'backbtn']))\n",
    ")\n",
    "\n",
    "# Listening quality score\n",
    "df_clean['listening_quality'] = np.where(\n",
    "    df_clean['percent_played'] >= 80, 'High',\n",
    "    np.where(df_clean['percent_played'] >= 50, 'Medium', 'Low')\n",
    ")\n",
    "\n",
    "# Time of day categories\n",
    "def categorize_time(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df_clean['time_of_day'] = df_clean['hour_of_day'].apply(categorize_time)\n",
    "\n",
    "print(\"Additional features created:\")\n",
    "print(f\"Skip rate: {df_clean['is_skip'].mean():.1%}\")\n",
    "print(f\"Listening quality distribution:\\n{df_clean['listening_quality'].value_counts()}\")\n",
    "print(f\"Time of day distribution:\\n{df_clean['time_of_day'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe01a09",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis - Listening Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze listening patterns by time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Listening by hour of day\n",
    "hourly_plays = df_clean.groupby('hour_of_day').size()\n",
    "axes[0, 0].bar(hourly_plays.index, hourly_plays.values, color='skyblue')\n",
    "axes[0, 0].set_title('Listening Activity by Hour of Day')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Number of Plays')\n",
    "\n",
    "# Listening by day of week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_plays = df_clean.groupby('day_of_week').size().reindex(day_order)\n",
    "axes[0, 1].bar(range(len(daily_plays)), daily_plays.values, color='lightcoral')\n",
    "axes[0, 1].set_title('Listening Activity by Day of Week')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Number of Plays')\n",
    "axes[0, 1].set_xticks(range(len(daily_plays)))\n",
    "axes[0, 1].set_xticklabels([day[:3] for day in day_order], rotation=45)\n",
    "\n",
    "# Listening by time of day categories\n",
    "time_plays = df_clean['time_of_day'].value_counts()\n",
    "axes[1, 0].pie(time_plays.values, labels=time_plays.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 0].set_title('Listening Distribution by Time of Day')\n",
    "\n",
    "# Monthly trends\n",
    "monthly_plays = df_clean.groupby('month').size()\n",
    "axes[1, 1].plot(monthly_plays.index, monthly_plays.values, marker='o', color='green')\n",
    "axes[1, 1].set_title('Listening Activity by Month')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Number of Plays')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print peak listening insights\n",
    "peak_hour = hourly_plays.idxmax()\n",
    "peak_day = daily_plays.idxmax()\n",
    "print(f\"Peak listening hour: {peak_hour}:00 ({hourly_plays[peak_hour]:,} plays)\")\n",
    "print(f\"Peak listening day: {peak_day} ({daily_plays[peak_day]:,} plays)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88187b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of listening patterns\n",
    "# Hour vs Day of Week heatmap\n",
    "pivot_data = df_clean.groupby(['day_of_week_num', 'hour_of_day']).size().unstack(fill_value=0)\n",
    "day_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_data, \n",
    "           yticklabels=day_labels,\n",
    "           cmap='YlOrRd', \n",
    "           annot=False,\n",
    "           fmt='d',\n",
    "           cbar_kws={'label': 'Number of Plays'})\n",
    "plt.title('Listening Activity Heatmap: Day of Week vs Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adf16e",
   "metadata": {},
   "source": [
    "## 5. Platform and Device Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ddcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform usage analysis\n",
    "platform_stats = df_clean.groupby('platform').agg({\n",
    "    'spotify_track_uri': 'count',\n",
    "    'seconds_played': ['sum', 'mean'],\n",
    "    'is_skip': 'mean',\n",
    "    'percent_played': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "platform_stats.columns = ['Total_Plays', 'Total_Time_Sec', 'Avg_Time_Sec', 'Skip_Rate', 'Avg_Percent_Played']\n",
    "platform_stats['Total_Time_Hours'] = (platform_stats['Total_Time_Sec'] / 3600).round(1)\n",
    "platform_stats['Skip_Rate_Percent'] = (platform_stats['Skip_Rate'] * 100).round(1)\n",
    "\n",
    "print(\"Platform Comparison:\")\n",
    "print(platform_stats)\n",
    "\n",
    "# Visualize platform metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total plays by platform\n",
    "platforms = platform_stats.index\n",
    "axes[0, 0].bar(platforms, platform_stats['Total_Plays'], color=['#1DB954', '#FF6B6B', '#4ECDC4'])\n",
    "axes[0, 0].set_title('Total Plays by Platform')\n",
    "axes[0, 0].set_ylabel('Number of Plays')\n",
    "\n",
    "# Average listening time by platform\n",
    "axes[0, 1].bar(platforms, platform_stats['Avg_Time_Sec'], color=['#1DB954', '#FF6B6B', '#4ECDC4'])\n",
    "axes[0, 1].set_title('Average Listening Time by Platform')\n",
    "axes[0, 1].set_ylabel('Seconds')\n",
    "\n",
    "# Skip rate by platform\n",
    "axes[1, 0].bar(platforms, platform_stats['Skip_Rate_Percent'], color=['#1DB954', '#FF6B6B', '#4ECDC4'])\n",
    "axes[1, 0].set_title('Skip Rate by Platform')\n",
    "axes[1, 0].set_ylabel('Skip Rate (%)')\n",
    "\n",
    "# Average percent played by platform\n",
    "axes[1, 1].bar(platforms, platform_stats['Avg_Percent_Played'], color=['#1DB954', '#FF6B6B', '#4ECDC4'])\n",
    "axes[1, 1].set_title('Average Percent Played by Platform')\n",
    "axes[1, 1].set_ylabel('Percent Played')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform usage patterns by time\n",
    "platform_time = df_clean.groupby(['platform', 'time_of_day']).size().unstack(fill_value=0)\n",
    "platform_time_pct = platform_time.div(platform_time.sum(axis=1), axis=0) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "platform_time_pct.plot(kind='bar', stacked=True, \n",
    "                      color=['#FFE5B4', '#FFCC99', '#FF6B6B', '#4ECDC4'])\n",
    "plt.title('Platform Usage Distribution by Time of Day (%)')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Percentage of Usage')\n",
    "plt.legend(title='Time of Day', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Platform usage by time of day (%):\\n\")\n",
    "print(platform_time_pct.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb85fe",
   "metadata": {},
   "source": [
    "## 6. Skip Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a92070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall skip behavior analysis\n",
    "skip_summary = {\n",
    "    'Total Tracks': len(df_clean),\n",
    "    'Skipped Tracks': df_clean['is_skip'].sum(),\n",
    "    'Skip Rate': f\"{df_clean['is_skip'].mean():.1%}\",\n",
    "    'Avg Percent Played (All)': f\"{df_clean['percent_played'].mean():.1f}%\",\n",
    "    'Avg Percent Played (Non-Skip)': f\"{df_clean[~df_clean['is_skip']]['percent_played'].mean():.1f}%\",\n",
    "    'Avg Percent Played (Skip)': f\"{df_clean[df_clean['is_skip']]['percent_played'].mean():.1f}%\"\n",
    "}\n",
    "\n",
    "print(\"Skip Behavior Summary:\")\n",
    "for key, value in skip_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Skip behavior by different factors\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Skip rate by platform\n",
    "skip_by_platform = df_clean.groupby('platform')['is_skip'].mean() * 100\n",
    "axes[0, 0].bar(skip_by_platform.index, skip_by_platform.values, color='coral')\n",
    "axes[0, 0].set_title('Skip Rate by Platform')\n",
    "axes[0, 0].set_ylabel('Skip Rate (%)')\n",
    "\n",
    "# Skip rate by time of day\n",
    "skip_by_time = df_clean.groupby('time_of_day')['is_skip'].mean() * 100\n",
    "axes[0, 1].bar(skip_by_time.index, skip_by_time.values, color='lightblue')\n",
    "axes[0, 1].set_title('Skip Rate by Time of Day')\n",
    "axes[0, 1].set_ylabel('Skip Rate (%)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Skip rate by shuffle mode\n",
    "skip_by_shuffle = df_clean.groupby('shuffle')['is_skip'].mean() * 100\n",
    "axes[1, 0].bar(['No Shuffle', 'Shuffle'], skip_by_shuffle.values, color='lightgreen')\n",
    "axes[1, 0].set_title('Skip Rate by Shuffle Mode')\n",
    "axes[1, 0].set_ylabel('Skip Rate (%)')\n",
    "\n",
    "# Skip rate by hour of day\n",
    "skip_by_hour = df_clean.groupby('hour_of_day')['is_skip'].mean() * 100\n",
    "axes[1, 1].plot(skip_by_hour.index, skip_by_hour.values, marker='o', color='purple')\n",
    "axes[1, 1].set_title('Skip Rate by Hour of Day')\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Skip Rate (%)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2137d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze skip reasons\n",
    "print(\"Analysis of Reason End (Why tracks stopped):\")\n",
    "reason_end_counts = df_clean['reason_end'].value_counts()\n",
    "print(reason_end_counts)\n",
    "\n",
    "# Skip rate by reason_end\n",
    "skip_by_reason_end = df_clean.groupby('reason_end')['is_skip'].mean() * 100\n",
    "skip_by_reason_end = skip_by_reason_end.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(skip_by_reason_end)), skip_by_reason_end.values, color='orange')\n",
    "plt.title('Skip Rate by Reason End')\n",
    "plt.xlabel('Reason End')\n",
    "plt.ylabel('Skip Rate (%)')\n",
    "plt.xticks(range(len(skip_by_reason_end)), skip_by_reason_end.index, rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSkip Rate by Reason End:\")\n",
    "for reason, rate in skip_by_reason_end.items():\n",
    "    print(f\"{reason}: {rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most skipped artists and tracks\n",
    "# Most skipped artists (by count)\n",
    "artist_skip_stats = df_clean.groupby('artist_name').agg({\n",
    "    'spotify_track_uri': 'count',\n",
    "    'is_skip': ['sum', 'mean']\n",
    "}).round(3)\n",
    "artist_skip_stats.columns = ['Total_Plays', 'Total_Skips', 'Skip_Rate']\n",
    "artist_skip_stats = artist_skip_stats[artist_skip_stats['Total_Plays'] >= 10]  # Filter for artists with at least 10 plays\n",
    "\n",
    "# Top 10 most skipped artists by skip rate\n",
    "most_skipped_artists = artist_skip_stats.sort_values('Skip_Rate', ascending=False).head(10)\n",
    "print(\"Top 10 Artists with Highest Skip Rates (min 10 plays):\")\n",
    "print(most_skipped_artists)\n",
    "\n",
    "# Top 10 least skipped artists\n",
    "least_skipped_artists = artist_skip_stats.sort_values('Skip_Rate', ascending=True).head(10)\n",
    "print(\"\\nTop 10 Artists with Lowest Skip Rates (min 10 plays):\")\n",
    "print(least_skipped_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1882c",
   "metadata": {},
   "source": [
    "## 7. Session Analysis and Sessionization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement sessionization logic (30-minute gap rule)\n",
    "# Sort by timestamp\n",
    "df_sessions = df_clean.sort_values('timestamp').copy()\n",
    "\n",
    "# Calculate time differences between consecutive plays\n",
    "df_sessions['time_diff'] = df_sessions['timestamp'].diff()\n",
    "\n",
    "# Create session breaks where gap > 30 minutes\n",
    "session_break_threshold = timedelta(minutes=30)\n",
    "df_sessions['is_session_start'] = (\n",
    "    (df_sessions['time_diff'] > session_break_threshold) | \n",
    "    (df_sessions['time_diff'].isna())\n",
    ")\n",
    "\n",
    "# Assign session IDs\n",
    "df_sessions['session_id'] = df_sessions['is_session_start'].cumsum()\n",
    "\n",
    "print(f\"Total number of sessions identified: {df_sessions['session_id'].nunique()}\")\n",
    "print(f\"Average tracks per session: {len(df_sessions) / df_sessions['session_id'].nunique():.1f}\")\n",
    "\n",
    "# Calculate session-level metrics\n",
    "session_stats = df_sessions.groupby('session_id').agg({\n",
    "    'timestamp': ['min', 'max'],\n",
    "    'spotify_track_uri': 'count',\n",
    "    'seconds_played': 'sum',\n",
    "    'is_skip': 'mean',\n",
    "    'platform': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]  # Most common platform in session\n",
    "}).round(2)\n",
    "\n",
    "session_stats.columns = ['Session_Start', 'Session_End', 'Tracks_Count', 'Total_Seconds', 'Skip_Rate', 'Primary_Platform']\n",
    "\n",
    "# Calculate session duration\n",
    "session_stats['Session_Duration_Minutes'] = (\n",
    "    (session_stats['Session_End'] - session_stats['Session_Start']).dt.total_seconds() / 60\n",
    ").round(1)\n",
    "\n",
    "session_stats['Total_Minutes'] = (session_stats['Total_Seconds'] / 60).round(1)\n",
    "\n",
    "print(\"\\nSession Statistics Summary:\")\n",
    "print(session_stats.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d46962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize session characteristics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Session duration distribution\n",
    "axes[0, 0].hist(session_stats['Session_Duration_Minutes'], bins=50, color='skyblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Session Durations')\n",
    "axes[0, 0].set_xlabel('Session Duration (Minutes)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(session_stats['Session_Duration_Minutes'].median(), color='red', \n",
    "                  linestyle='--', label=f'Median: {session_stats[\"Session_Duration_Minutes\"].median():.1f} min')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Tracks per session distribution\n",
    "axes[0, 1].hist(session_stats['Tracks_Count'], bins=30, color='lightgreen', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Tracks per Session')\n",
    "axes[0, 1].set_xlabel('Number of Tracks')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(session_stats['Tracks_Count'].median(), color='red', \n",
    "                  linestyle='--', label=f'Median: {session_stats[\"Tracks_Count\"].median():.0f} tracks')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Session skip rate distribution\n",
    "axes[1, 0].hist(session_stats['Skip_Rate'] * 100, bins=30, color='coral', alpha=0.7)\n",
    "axes[1, 0].set_title('Distribution of Session Skip Rates')\n",
    "axes[1, 0].set_xlabel('Skip Rate (%)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(session_stats['Skip_Rate'].median() * 100, color='red', \n",
    "                  linestyle='--', label=f'Median: {session_stats[\"Skip_Rate\"].median()*100:.1f}%')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Platform distribution in sessions\n",
    "platform_sessions = session_stats['Primary_Platform'].value_counts()\n",
    "axes[1, 1].pie(platform_sessions.values, labels=platform_sessions.index, autopct='%1.1f%%')\n",
    "axes[1, 1].set_title('Primary Platform Distribution in Sessions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Session insights\n",
    "print(\"\\nSession Insights:\")\n",
    "print(f\"Average session duration: {session_stats['Session_Duration_Minutes'].mean():.1f} minutes\")\n",
    "print(f\"Median session duration: {session_stats['Session_Duration_Minutes'].median():.1f} minutes\")\n",
    "print(f\"Average tracks per session: {session_stats['Tracks_Count'].mean():.1f}\")\n",
    "print(f\"Average session skip rate: {session_stats['Skip_Rate'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b91a3",
   "metadata": {},
   "source": [
    "## 8. Top Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e956bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top tracks analysis\n",
    "track_stats = df_clean.groupby(['track_name', 'artist_name']).agg({\n",
    "    'spotify_track_uri': 'count',\n",
    "    'seconds_played': 'sum',\n",
    "    'is_skip': 'mean',\n",
    "    'percent_played': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "track_stats.columns = ['Play_Count', 'Total_Seconds', 'Skip_Rate', 'Avg_Percent_Played']\n",
    "track_stats['Total_Minutes'] = (track_stats['Total_Seconds'] / 60).round(1)\n",
    "\n",
    "# Top tracks by play count\n",
    "top_tracks_plays = track_stats.sort_values('Play_Count', ascending=False).head(15)\n",
    "print(\"Top 15 Tracks by Play Count:\")\n",
    "print(top_tracks_plays[['Play_Count', 'Total_Minutes', 'Skip_Rate']])\n",
    "\n",
    "# Top tracks by total listening time\n",
    "top_tracks_time = track_stats.sort_values('Total_Minutes', ascending=False).head(15)\n",
    "print(\"\\nTop 15 Tracks by Total Listening Time:\")\n",
    "print(top_tracks_time[['Play_Count', 'Total_Minutes', 'Skip_Rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81220a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top artists analysis\n",
    "artist_stats = df_clean.groupby('artist_name').agg({\n",
    "    'spotify_track_uri': 'count',\n",
    "    'track_name': 'nunique',\n",
    "    'seconds_played': 'sum',\n",
    "    'is_skip': 'mean',\n",
    "    'percent_played': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "artist_stats.columns = ['Total_Plays', 'Unique_Tracks', 'Total_Seconds', 'Skip_Rate', 'Avg_Percent_Played']\n",
    "artist_stats['Total_Hours'] = (artist_stats['Total_Seconds'] / 3600).round(1)\n",
    "\n",
    "# Top artists by play count\n",
    "top_artists_plays = artist_stats.sort_values('Total_Plays', ascending=False).head(15)\n",
    "print(\"Top 15 Artists by Play Count:\")\n",
    "print(top_artists_plays[['Total_Plays', 'Unique_Tracks', 'Total_Hours', 'Skip_Rate']])\n",
    "\n",
    "# Visualize top artists\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Top 10 artists by plays\n",
    "top_10_artists = top_artists_plays.head(10)\n",
    "axes[0].barh(range(len(top_10_artists)), top_10_artists['Total_Plays'], color='lightblue')\n",
    "axes[0].set_yticks(range(len(top_10_artists)))\n",
    "axes[0].set_yticklabels([name[:20] + '...' if len(name) > 20 else name for name in top_10_artists.index])\n",
    "axes[0].set_xlabel('Total Plays')\n",
    "axes[0].set_title('Top 10 Artists by Play Count')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Top 10 artists by listening time\n",
    "top_10_time = artist_stats.sort_values('Total_Hours', ascending=False).head(10)\n",
    "axes[1].barh(range(len(top_10_time)), top_10_time['Total_Hours'], color='lightcoral')\n",
    "axes[1].set_yticks(range(len(top_10_time)))\n",
    "axes[1].set_yticklabels([name[:20] + '...' if len(name) > 20 else name for name in top_10_time.index])\n",
    "axes[1].set_xlabel('Total Hours')\n",
    "axes[1].set_title('Top 10 Artists by Listening Time')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b1054",
   "metadata": {},
   "source": [
    "## 9. Key Performance Indicators (KPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8779a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key business metrics\n",
    "total_listening_hours = df_clean['seconds_played'].sum() / 3600\n",
    "unique_tracks = df_clean['spotify_track_uri'].nunique()\n",
    "unique_artists = df_clean['artist_name'].nunique()\n",
    "daily_active_sessions = df_sessions.groupby(df_sessions['Session_Start'].dt.date)['session_id'].nunique().mean()\n",
    "avg_session_length = session_stats['Session_Duration_Minutes'].mean()\n",
    "avg_tracks_per_session = session_stats['Tracks_Count'].mean()\n",
    "overall_skip_rate = df_clean['is_skip'].mean()\n",
    "avg_percent_played = df_clean['percent_played'].mean()\n",
    "\n",
    "# Create KPI dashboard\n",
    "kpis = {\n",
    "    'Total Listening Hours': f\"{total_listening_hours:,.1f}\",\n",
    "    'Total Tracks Played': f\"{len(df_clean):,}\",\n",
    "    'Unique Tracks': f\"{unique_tracks:,}\",\n",
    "    'Unique Artists': f\"{unique_artists:,}\",\n",
    "    'Total Sessions': f\"{df_sessions['session_id'].nunique():,}\",\n",
    "    'Avg Daily Sessions': f\"{daily_active_sessions:.1f}\",\n",
    "    'Avg Session Length (min)': f\"{avg_session_length:.1f}\",\n",
    "    'Avg Tracks per Session': f\"{avg_tracks_per_session:.1f}\",\n",
    "    'Overall Skip Rate': f\"{overall_skip_rate:.1%}\",\n",
    "    'Avg Percent Played': f\"{avg_percent_played:.1f}%\",\n",
    "    'Platform Distribution': f\"Web: {(df_clean['platform'] == 'web player').mean():.1%}, iOS: {(df_clean['platform'] == 'iOS').mean():.1%}, Android: {(df_clean['platform'] == 'Android').mean():.1%}\"\n",
    "}\n",
    "\n",
    "print(\"ðŸŽµ SPOTIFY STREAMING ANALYTICS - KEY PERFORMANCE INDICATORS ðŸŽµ\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for kpi, value in kpis.items():\n",
    "    print(f\"{kpi:<25}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181bc19",
   "metadata": {},
   "source": [
    "## 10. Data Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets for further analysis\n",
    "# Save the main cleaned dataset\n",
    "df_clean.to_csv('../data/spotify_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved to: ../data/spotify_cleaned.csv\")\n",
    "\n",
    "# Save session-level data\n",
    "session_export = df_sessions[['session_id', 'timestamp', 'spotify_track_uri', 'platform', \n",
    "                             'seconds_played', 'is_skip', 'time_of_day', 'day_of_week']]\n",
    "session_export.to_csv('../data/spotify_sessions.csv', index=False)\n",
    "print(\"Session data saved to: ../data/spotify_sessions.csv\")\n",
    "\n",
    "# Save aggregated session statistics\n",
    "session_stats.to_csv('../data/session_statistics.csv')\n",
    "print(\"Session statistics saved to: ../data/session_statistics.csv\")\n",
    "\n",
    "# Save top content analysis\n",
    "top_tracks_plays.to_csv('../data/top_tracks.csv')\n",
    "top_artists_plays.to_csv('../data/top_artists.csv')\n",
    "print(\"Top content analysis saved to: ../data/top_tracks.csv and ../data/top_artists.csv\")\n",
    "\n",
    "print(\"\\nâœ… All datasets exported successfully for further analysis!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
